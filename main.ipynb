{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import backoff\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# FAST_DOWNWARD_ALIAS = \"lama\"\n",
    "FAST_DOWNWARD_ALIAS = \"seq-opt-fdss-1\"\n",
    "OPENAI_API_KEY=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(x):\n",
    "    return x.strip()\n",
    "# extract a cost value from a string x\n",
    "def get_cost(x):\n",
    "    splitted = x.split()\n",
    "    counter = 0\n",
    "    found = False\n",
    "    cost = 1e5\n",
    "    for i, xx in enumerate(splitted):\n",
    "        if xx == \"cost\":\n",
    "            counter = i\n",
    "            found = True\n",
    "            break\n",
    "    if found:\n",
    "        cost = float(splitted[counter+2])\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function populates a list of tasks based on the files present in the specified domain's directory.\n",
    "def get_tasks(domain_name):\n",
    "    domain_path = f\"./domain/{domain_name}\"\n",
    "    task_files = []\n",
    "    # Iterate over all .nl files in the domain directory\n",
    "    for file_name in glob.glob(f\"{domain_path}/*.nl\"):\n",
    "        base_file_name = os.path.basename(file_name)\n",
    "        if \"domain\" not in base_file_name and \"p_example\" not in base_file_name:\n",
    "            if os.path.exists(file_name.replace(\"nl\", \"pddl\")):\n",
    "                task_files.append(base_file_name)\n",
    "                \n",
    "    sorted_task_files = sorted(task_files)\n",
    "    tasks = [(file, file.replace(\"nl\", \"pddl\")) for file in sorted_task_files]\n",
    "    return tasks\n",
    "\n",
    "# Reads and returns the processed content of the natural language and PDDL files for a specific task.\n",
    "def get_task(tasks, i,domain_name):\n",
    "    nl_f, pddl_f = f\"./domain/{domain_name}/{tasks[i][0]}\", f\"./domain/{domain_name}/{tasks[i][1]}\"\n",
    "    with open(nl_f, 'r') as f:\n",
    "        nl = f.read()\n",
    "    with open(pddl_f, 'r') as f:\n",
    "        pddl = f.read()\n",
    "    return postprocess(nl), postprocess(pddl)\n",
    "    \n",
    "# Reads and returns the processed content of the context files (NL, PDDL, SOL)\n",
    "def get_context(domain_name):\n",
    "    nl_f   = f\"./domain/{domain_name}/p_example.nl\"\n",
    "    pddl_f = f\"./domain/{domain_name}/p_example.pddl\"\n",
    "    sol_f  = f\"./domain/{domain_name}/p_example.sol\"\n",
    "    with open(nl_f, 'r') as f:\n",
    "        nl   = f.read()\n",
    "    with open(pddl_f, 'r') as f:\n",
    "        pddl = f.read()\n",
    "    with open(sol_f, 'r') as f:\n",
    "        sol  = f.read()\n",
    "    return postprocess(nl), postprocess(pddl), postprocess(sol)\n",
    "\n",
    "# Reads and returns the processed content of the domain PDDL file.\n",
    "def get_domain_pddl(domain_name):\n",
    "    domain_pddl_f = f\"./domain/{domain_name}/domain.pddl\"\n",
    "    with open(domain_pddl_f, 'r') as f:\n",
    "        domain_pddl = f.read()\n",
    "    return postprocess(domain_pddl)\n",
    "\n",
    "# Reads and returns the processed content of the domain NL file.\n",
    "def get_domain_nl(domain_name):\n",
    "    domain_nl_f = f\"./domain/{domain_name}/domain.nl\"\n",
    "    try:\n",
    "        with open(domain_nl_f, 'r') as f:\n",
    "            domain_nl = f.read()\n",
    "    except:\n",
    "        domain_nl = \"Nothing\"\n",
    "    return postprocess(domain_nl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Prompts for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_prompt(task_nl, domain_nl):\n",
    "    # Baseline (LLM-as-Planner): directly ask the LLM for plan\n",
    "    prompt = f\"{domain_nl} \\n\" + \\\n",
    "                f\"Now consider a planning problem. \" + \\\n",
    "                f\"The problem description is: \\n {task_nl} \\n\" + \\\n",
    "                f\"Can you provide an optimal plan, in the way of a \" + \\\n",
    "                f\"sequence of behaviors, to solve the problem?\"\n",
    "    return prompt\n",
    "\n",
    "def create_llm_ic_prompt(task_nl, domain_nl, context):\n",
    "    # Baseline (LLM-as-Planner with context): directly ask the LLM for plan\n",
    "    context_nl, context_pddl, context_sol = context\n",
    "    prompt = f\"{domain_nl} \\n\" + \\\n",
    "             f\"An example planning problem is: \\n {context_nl} \\n\" + \\\n",
    "             f\"A plan for the example problem is: \\n {context_sol} \\n\" + \\\n",
    "             f\"Now I have a new planning problem and its description is: \\n {task_nl} \\n\" + \\\n",
    "             f\"Can you provide an optimal plan, in the way of a \" + \\\n",
    "             f\"sequence of behaviors, to solve the problem?\"\n",
    "    return prompt\n",
    "\n",
    "def create_llm_pddl_prompt(\n",
    "        task_nl, domain_nl):\n",
    "    # Modified BaseLine (LLM+Planner w/o context), no context, create the problem PDDL\n",
    "    prompt = f\"{domain_nl} \\n\" + \\\n",
    "                f\"Now consider a planning problem. \" + \\\n",
    "                f\"The problem description is: \\n {task_nl} \\n\" + \\\n",
    "                f\"Provide me with the problem PDDL file that describes \" + \\\n",
    "                f\"the planning problem directly without further explanations?\" +\\\n",
    "                f\"Keep the domain name consistent in the problem PDDL. Only return the PDDL file. Do not return anything else.\"\n",
    "    return prompt\n",
    "\n",
    "def create_llm_ic_pddl_prompt( task_nl, domain_pddl, context):\n",
    "    # Modified BaseLine(LLM+Planner), create the problem PDDL given the context\n",
    "    context_nl, context_pddl, context_sol = context\n",
    "    prompt = f\"I want you to solve planning problems. \" + \\\n",
    "                f\"An example planning problem is: \\n {context_nl} \\n\" + \\\n",
    "                f\"The problem PDDL file to this problem is: \\n {context_pddl} \\n\" + \\\n",
    "                f\"Now I have a new planning problem and its description is: \\n {task_nl} \\n\" + \\\n",
    "                f\"Provide me with the problem PDDL file that describes \" + \\\n",
    "                f\"the new planning problem directly without further explanations? Only return the PDDL file. Do not return anything else.\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interact with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(prompt_text, api_key):\n",
    "    # Create an OpenAI client\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Define the parameters for the chat completion\n",
    "    chat_params = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_text},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Create the chat completion\n",
    "    response = client.chat.completions.create(**chat_params)\n",
    "\n",
    "    # Extract the result text from the completion\n",
    "    result_text = response.choices[0].message.content\n",
    "\n",
    "    return result_text\n",
    "\n",
    "def plan_to_language( plan, task_nl, domain_pddl,context_pddl,context_sol):\n",
    "    domain_pddl_ = \" \".join(domain_pddl.split())\n",
    "    task_nl_ = \" \".join(task_nl.split())\n",
    "    prompt = f\"An example PDDL plan is: \\n {context_pddl} \\n\" + \\\n",
    "                f\"The corresponding Natural Language Description of this PDDL plan is : \\n {context_sol} \\n\" + \\\n",
    "                f\"Now I have a new planning problem and its description is: \\n {task_nl_} \\n\" + \\\n",
    "                f\"The corresponding domain PDDL file is: \\n {domain_pddl_} \\n\" + \\\n",
    "                f\"The optimal PDDL plan is: \\n {plan} \\n\" + \\\n",
    "                f\"Transform the PDDL plan into a sequence of behaviors without further explanation.\"\n",
    "    res = query(prompt,OPENAI_API_KEY).strip() + \"\\n\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaseLine Model: Only LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_planner(domain_name,time_limit,tasks,task_number):\n",
    "    \"\"\"\n",
    "    Baseline method:\n",
    "        The LLM will be asked to directly give a plan based on the task description.\n",
    "    \"\"\"\n",
    "    domain_pddl      = get_domain_pddl(domain_name)\n",
    "    domain_pddl_file = f\"./domain/{domain_name}/domain.pddl\"\n",
    "    domain_nl        = get_domain_nl(domain_name)\n",
    "    domain_nl_file   = f\"./domain/{domain_name}/domain.nl\"\n",
    "\n",
    "    # create the tmp / result folders\n",
    "    problem_folder = f\"./experiments/problems/llm\"\n",
    "    plan_folder    = f\"./experiments/plans/llm\"\n",
    "    result_folder  = f\"./experiments/results/llm\"\n",
    "\n",
    "    if not os.path.exists(problem_folder):\n",
    "        os.system(f\"mkdir -p {problem_folder}\")\n",
    "    if not os.path.exists(plan_folder):\n",
    "        os.system(f\"mkdir -p {plan_folder}\")\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.system(f\"mkdir -p {result_folder}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # A. generate problem pddl file\n",
    "    # task_suffix        = f\"{domain_name}/{tasks[task_number][1]}\"\n",
    "    task_suffix        = f\"{tasks[task_number][1]}\"\n",
    "    task_nl, task_pddl = get_task(tasks,task_number,domain_name) \n",
    "    prompt             = create_llm_prompt(task_nl, domain_nl)\n",
    "    text_plan          = query(prompt,OPENAI_API_KEY)\n",
    "\n",
    "    # B. write the problem file into the problem folder\n",
    "    text_plan_file_name = f\"./experiments/results/llm/{task_suffix}\"\n",
    "    with open(text_plan_file_name, \"w\") as f:\n",
    "        f.write(text_plan)\n",
    "    end_time = time.time()\n",
    "    print(f\"[info] task {task_number} takes {end_time - start_time} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_ic_planner(domain_name,time_limit,tasks,task_number):\n",
    "    \"\"\"\n",
    "    Baseline method:\n",
    "        The LLM will be asked to directly give a plan based on the task description.\n",
    "    \"\"\"\n",
    "    context          = get_context(domain_name)\n",
    "    domain_pddl      = get_domain_pddl(domain_name)\n",
    "    domain_pddl_file = f\"./domain/{domain_name}/domain.pddl\"\n",
    "    domain_nl        = get_domain_nl(domain_name)\n",
    "    domain_nl_file   = f\"./domain/{domain_name}/domain.nl\"\n",
    "\n",
    "    # create the tmp / result folders\n",
    "    problem_folder = f\"./experiments/problems/llm_ic\"\n",
    "    plan_folder    = f\"./experiments/plans/llm_ic\"\n",
    "    result_folder  = f\"./experiments/results/llm_ic\"\n",
    "\n",
    "    if not os.path.exists(problem_folder):\n",
    "        os.system(f\"mkdir -p {problem_folder}\")\n",
    "    if not os.path.exists(plan_folder):\n",
    "        os.system(f\"mkdir -p {plan_folder}\")\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.system(f\"mkdir -p {result_folder}\")\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # A. generate problem pddl file\n",
    "    task_suffix        = f\"{tasks[task_number][1]}\"\n",
    "    task_nl, task_pddl = get_task(tasks,task_number,domain_name) \n",
    "    prompt             = create_llm_ic_prompt(task_nl, domain_nl, context)\n",
    "    text_plan          = query(prompt,OPENAI_API_KEY)\n",
    "\n",
    "    # B. write the problem file into the problem folder\n",
    "    text_plan_file_name = f\"./experiments/results/llm_ic/{task_suffix}\"\n",
    "    with open(text_plan_file_name, \"w\") as f:\n",
    "        f.write(text_plan)\n",
    "    end_time = time.time()\n",
    "    print(f\"[info] task {task_number} takes {end_time - start_time} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Model: LLM + Planner Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_pddl_planner(domain_name,time_limit,tasks,task_number):\n",
    "    \"\"\"\n",
    "    Baseline method:\n",
    "        Same as ours, except that no context is given. In other words, the LLM\n",
    "        will be asked to directly give a problem PDDL file without any context.\n",
    "    \"\"\"\n",
    "    domain_pddl      = get_domain_pddl(domain_name)\n",
    "    domain_pddl_file = f\"./domain/{domain_name}/domain.pddl\"\n",
    "    domain_nl        = get_domain_nl(domain_name)\n",
    "    domain_nl_file   = f\"./domain/{domain_name}/domain.nl\"\n",
    "\n",
    "    # create the tmp / result folders\n",
    "    problem_folder = f\"./experiments/problems/llm_pddl\"\n",
    "    plan_folder    = f\"./experiments/plans/llm_pddl\"\n",
    "    result_folder  = f\"./experiments/results/llm_pddl\"\n",
    "\n",
    "    if not os.path.exists(problem_folder):\n",
    "        os.system(f\"mkdir -p {problem_folder}\")\n",
    "    if not os.path.exists(plan_folder):\n",
    "        os.system(f\"mkdir -p {plan_folder}\")\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.system(f\"mkdir -p {result_folder}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # A. generate problem pddl file\n",
    "    task_suffix= f\"{tasks[task_number][1]}\"\n",
    "    task_nl, task_pddl = get_task(tasks,task_number,domain_name) \n",
    "    prompt = create_llm_pddl_prompt(task_nl, domain_pddl)\n",
    "\n",
    "    task_pddl_file_name = f\"./experiments/problems/llm_pddl/{task_suffix}\"\n",
    "    raw_result= query(prompt,OPENAI_API_KEY)\n",
    "\n",
    "    # B. write the problem file into the problem folder\n",
    "    with open(task_pddl_file_name, \"w\") as f:\n",
    "        f.write(raw_result)\n",
    "    time.sleep(1)\n",
    "\n",
    "    ## C. run fastforward to plan\n",
    "    plan_file_name = f\"./experiments/plans/llm_pddl/{task_suffix}\"\n",
    "    sas_file_name  = f\"./experiments/plans/llm_pddl/{task_suffix}.sas\"\n",
    "    validate_option = \"--validate\"  # \"--debug\" or \"--validate\" if you want to explicitly enable validation\n",
    "    os.system(f\"python ../downward/fast-downward.py --alias {FAST_DOWNWARD_ALIAS} \" + \\\n",
    "              f\"--search-time-limit {time_limit} --plan-file {plan_file_name} \" + \\\n",
    "              f\"--sas-file {sas_file_name} {validate_option} \" + \\\n",
    "              f\"{domain_pddl_file} {task_pddl_file_name}\")\n",
    "\n",
    "    # D. collect the least cost plan\n",
    "    best_cost = 1e10\n",
    "    best_plan = None\n",
    "    for fn in glob.glob(f\"{plan_file_name}\"):\n",
    "        with open(fn, \"r\") as f:\n",
    "            plans = f.readlines()\n",
    "            cost = get_cost(plans[-1])\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_plan = \"\\n\".join([p.strip() for p in plans[:-1]])\n",
    "\n",
    "    # E. translate the plan back to natural language, and write it to result\n",
    "    # '''\n",
    "    if best_plan:\n",
    "        plans_nl = plan_to_language(best_plan, task_nl, domain_nl, domain_pddl)\n",
    "        plan_nl_file_name = f\"./experiments/results/llm_pddl/{task_suffix}\"\n",
    "        with open(plan_nl_file_name, \"w\") as f:\n",
    "            f.write(plans_nl)\n",
    "    # '''\n",
    "    end_time = time.time()\n",
    "    if best_plan:\n",
    "        print(f\"[info] task {task_number} takes {end_time - start_time} sec, found a plan with cost {best_cost}\")\n",
    "    else:\n",
    "        print(f\"[info] task {task_number} takes {end_time - start_time} sec, no solution found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_ic_pddl_planner(domain_name,time_limit,tasks,task_number):\n",
    "    \"\"\"\n",
    "    Our method:\n",
    "        context: (task natural language, task problem PDDL)\n",
    "        Condition on the context (task description -> task problem PDDL),\n",
    "        LLM will be asked to provide the problem PDDL of a new task description.\n",
    "        Then, we use a planner to find the near optimal solution, and translate\n",
    "        that back to natural language.\n",
    "    \"\"\"\n",
    "    context          = get_context(domain_name)\n",
    "    domain_pddl      = get_domain_pddl(domain_name)\n",
    "    domain_pddl_file = f\"./domain/{domain_name}/domain.pddl\"\n",
    "    domain_nl        = get_domain_nl(domain_name)\n",
    "    domain_nl_file   = f\"./domain/{domain_name}/domain.nl\"\n",
    "\n",
    "    # create the tmp / result folders\n",
    "    problem_folder = f\"./experiments/problems/llm_ic_pddl\"\n",
    "    plan_folder    = f\"./experiments/plans/llm_ic_pddl\"\n",
    "    result_folder  = f\"./experiments/results/llm_ic_pddl\"\n",
    "\n",
    "    if not os.path.exists(problem_folder):\n",
    "        os.system(f\"mkdir -p {problem_folder}\")\n",
    "    if not os.path.exists(plan_folder):\n",
    "        os.system(f\"mkdir -p {plan_folder}\")\n",
    "    if not os.path.exists(result_folder):\n",
    "        os.system(f\"mkdir -p {result_folder}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # A. generate problem pddl file\n",
    "    task_suffix= f\"{tasks[task_number][1]}\"\n",
    "    task_nl, task_pddl = get_task(tasks,task_number,domain_name) \n",
    "    prompt = create_llm_ic_pddl_prompt(task_nl, domain_pddl, context)\n",
    "\n",
    "    task_pddl_file_name = f\"./experiments/problems/llm_ic_pddl/{task_suffix}\"\n",
    "    \n",
    "    raw_result= query(prompt,OPENAI_API_KEY)\n",
    "\n",
    "    # B. write the problem file into the problem folder\n",
    "    with open(task_pddl_file_name, \"w\") as f:\n",
    "        f.write(raw_result)\n",
    "    time.sleep(1)\n",
    "\n",
    "    ## C. run fastforward to generate plan\n",
    "    plan_file_name = f\"./experiments/plans/llm_ic_pddl/{task_suffix}\"\n",
    "    sas_file_name  = f\"./experiments/plans/llm_ic_pddl/{task_suffix}.sas\"\n",
    "    validate_option = \"--validate\"  # \"--debug\" or \"--validate\" if you want to explicitly enable validation\n",
    "    os.system(f\"python ../downward/fast-downward.py --alias {FAST_DOWNWARD_ALIAS} \" + \\\n",
    "              f\"--search-time-limit {time_limit} --plan-file {plan_file_name} \" + \\\n",
    "              f\"--sas-file {sas_file_name} {validate_option} \" + \\\n",
    "              f\"{domain_pddl_file} {task_pddl_file_name}\")\n",
    "\n",
    "    # D. collect the least cost plan\n",
    "    best_cost = 1e10\n",
    "    best_plan = None\n",
    "    for fn in glob.glob(f\"{plan_file_name}\"):\n",
    "        with open(fn, \"r\") as f:\n",
    "            plans = f.readlines()\n",
    "            cost = get_cost(plans[-1])\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_plan = \"\\n\".join([p.strip() for p in plans[:-1]])\n",
    "\n",
    "    # E. translate the plan back to natural language, and write it to result\n",
    "    # '''\n",
    "    if best_plan:\n",
    "        plans_nl = plan_to_language(best_plan, task_nl, domain_nl, domain_pddl)\n",
    "        plan_nl_file_name = f\"./experiments/results/llm_ic_pddl/{task_suffix}\"\n",
    "        with open(plan_nl_file_name, \"w\") as f:\n",
    "            f.write(plans_nl)\n",
    "    # '''\n",
    "    end_time = time.time()\n",
    "    if best_plan:\n",
    "        print(f\"[info] task {task_number} takes {end_time - start_time} sec, found a plan with cost {best_cost}\")\n",
    "    else:\n",
    "        print(f\"[info] task {task_number} takes {end_time - start_time} sec, no solution found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     planner time limit: None\n",
      "INFO     planner memory limit: None\n",
      "\n",
      "INFO     Running translator.\n",
      "INFO     translator stdin: None\n",
      "INFO     translator time limit: None\n",
      "INFO     translator memory limit: None\n",
      "INFO     translator command line string: /home/jainav/python-environments/pe-llm/bin/python /home/jainav/Work/PE-LLM/downward/builds/release/bin/translate/translate.py ./domain/blocksworld/domain.pddl ./experiments/problems/llm_ic_pddl/p15.pddl --sas-file ./experiments/plans/llm_ic_pddl/p15.pddl.sas\n",
      "Parsing...\n",
      "Parsing: [0.000s CPU, 0.001s wall-clock]\n",
      "Normalizing task... [0.000s CPU, 0.000s wall-clock]\n",
      "Instantiating...\n",
      "Generating Datalog program... [0.000s CPU, 0.000s wall-clock]\n",
      "Normalizing Datalog program...\n",
      "Normalizing Datalog program: [0.000s CPU, 0.001s wall-clock]\n",
      "Preparing model... [0.010s CPU, 0.000s wall-clock]\n",
      "Generated 21 rules.\n",
      "Computing model... [0.000s CPU, 0.002s wall-clock]\n",
      "339 relevant atoms\n",
      "227 auxiliary atoms\n",
      "566 final queue length\n",
      "944 total queue pushes\n",
      "Completing instantiation... [0.000s CPU, 0.003s wall-clock]\n",
      "Instantiating: [0.010s CPU, 0.007s wall-clock]\n",
      "Computing fact groups...\n",
      "Finding invariants...\n",
      "10 initial candidates\n",
      "Finding invariants: [0.000s CPU, 0.002s wall-clock]\n",
      "Checking invariant weight... [0.000s CPU, 0.000s wall-clock]\n",
      "Instantiating groups... [0.000s CPU, 0.000s wall-clock]\n",
      "Collecting mutex groups... [0.000s CPU, 0.000s wall-clock]\n",
      "Choosing groups...\n",
      "12 uncovered facts\n",
      "Choosing groups: [0.000s CPU, 0.000s wall-clock]\n",
      "Building translation key... [0.000s CPU, 0.000s wall-clock]\n",
      "Computing fact groups: [0.000s CPU, 0.003s wall-clock]\n",
      "Building STRIPS to SAS dictionary... [0.000s CPU, 0.000s wall-clock]\n",
      "Building dictionary for full mutex groups... [0.000s CPU, 0.000s wall-clock]\n",
      "Building mutex information...\n",
      "Building mutex information: [0.000s CPU, 0.000s wall-clock]\n",
      "Translating task...\n",
      "Processing axioms...\n",
      "Simplifying axioms... [0.000s CPU, 0.000s wall-clock]\n",
      "Translator axioms removed by simplifying: 0\n",
      "Computing negative axioms... [0.010s CPU, 0.000s wall-clock]\n",
      "Processing axioms: [0.010s CPU, 0.000s wall-clock]\n",
      "Translating task: [0.010s CPU, 0.005s wall-clock]\n",
      "261 effect conditions simplified\n",
      "0 implied preconditions added\n",
      "Detecting unreachable propositions...\n",
      "0 operators removed\n",
      "0 axioms removed\n",
      "20 propositions removed\n",
      "Detecting unreachable propositions: [0.000s CPU, 0.002s wall-clock]\n",
      "Reordering and filtering variables...\n",
      "20 of 20 variables necessary.\n",
      "11 of 20 mutex groups necessary.\n",
      "180 of 180 operators necessary.\n",
      "0 of 0 axiom rules necessary.\n",
      "Reordering and filtering variables: [0.000s CPU, 0.002s wall-clock]\n",
      "Translator variables: 20\n",
      "Translator derived variables: 0\n",
      "Translator facts: 121\n",
      "Translator goal facts: 7\n",
      "Translator mutex groups: 11\n",
      "Translator total mutex groups size: 110\n",
      "Translator operators: 180\n",
      "Translator axioms: 0\n",
      "Translator task size: 1581\n",
      "Translator peak memory: 33232 KB\n",
      "Writing output... [0.000s CPU, 0.001s wall-clock]\n",
      "Done! [0.020s CPU, 0.024s wall-clock]\n",
      "translate exit code: 0\n",
      "\n",
      "INFO     Running search (release).\n",
      "INFO     search portfolio: /home/jainav/Work/PE-LLM/downward/driver/portfolios/seq_opt_fdss_1.py\n",
      "remaining time: 200.0\n",
      "config 0: relative time 175, remaining 1631\n",
      "args: ['/home/jainav/Work/PE-LLM/downward/builds/release/bin/downward', '--search', 'astar(merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1))', '--internal-plan-file', './experiments/plans/llm_ic_pddl/p15.pddl']\n",
      "INFO     search stdin: ./experiments/plans/llm_ic_pddl/p15.pddl.sas\n",
      "INFO     search time limit: 21s\n",
      "INFO     search memory limit: None\n",
      "INFO     search command line string: /home/jainav/Work/PE-LLM/downward/builds/release/bin/downward --search 'astar(merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1))' --internal-plan-file ./experiments/plans/llm_ic_pddl/p15.pddl < ./experiments/plans/llm_ic_pddl/p15.pddl.sas\n",
      "[t=0.000000s, 9792 KB] reading input...\n",
      "[t=0.000000s, 9792 KB] done reading input!\n",
      "[t=0.000000s, 10188 KB] Initializing merge-and-shrink heuristic...\n",
      "[t=0.000000s, 10188 KB] Running merge-and-shrink algorithm...\n",
      "[t=0.000000s, 10188 KB] Merge strategy options:\n",
      "[t=0.000000s, 10188 KB] Type: precomputed\n",
      "[t=0.000000s, 10188 KB] Merge tree options: \n",
      "[t=0.000000s, 10188 KB] Type: linear\n",
      "[t=0.000000s, 10188 KB] Update option: use random\n",
      "[t=0.000000s, 10188 KB] Variable order type: by reverse level\n",
      "\n",
      "[t=0.000000s, 10188 KB] Options related to size limits and shrinking: \n",
      "[t=0.000000s, 10188 KB] Transition system size limit: 2147483647\n",
      "[t=0.000000s, 10188 KB] Transition system size limit right before merge: 2147483647\n",
      "[t=0.000000s, 10188 KB] Threshold to trigger shrinking right before merge: 1\n",
      "\n",
      "[t=0.000000s, 10188 KB] Shrink strategy options: \n",
      "[t=0.000000s, 10188 KB] Type: bisimulation\n",
      "[t=0.000000s, 10188 KB] Bisimulation type: greedy\n",
      "[t=0.000000s, 10188 KB] At limit: return\n",
      "\n",
      "[t=0.000000s, 10188 KB] Pruning unreachable states: yes\n",
      "[t=0.000000s, 10188 KB] Pruning irrelevant states: yes\n",
      "\n",
      "[t=0.000000s, 10188 KB] Label reduction options:\n",
      "[t=0.000000s, 10188 KB] Before merging: disabled\n",
      "[t=0.000000s, 10188 KB] Before shrinking: enabled\n",
      "[t=0.000000s, 10188 KB] Method: all transition systems with fixpoint computation\n",
      "[t=0.000000s, 10188 KB] System order: random\n",
      "\n",
      "[t=0.000000s, 10188 KB] Main loop max time in seconds: inf\n",
      "\n",
      "\n",
      "[t=0.000000s, 10188 KB] Building atomic transition systems... \n",
      "[t=0.000000s, 10188 KB] M&S algorithm timer: 0.000000s (after computation of atomic factors)\n",
      "\n",
      "[t=0.000000s, 10188 KB] Starting main loop without a time limit.\n",
      "[t=0.000000s, 10188 KB] building causal graph...done! [t=0.000000s]\n",
      "[t=0.000000s, 10188 KB] Next pair of indices: (0, 1)\n",
      "[t=0.000000s, 10188 KB] M&S algorithm main loop timer: 0.000000s (after computation of next merge)\n",
      "[t=0.003999s, 10188 KB] M&S algorithm main loop timer: 0.003999s (after shrinking)\n",
      "[t=0.003999s, 10188 KB] M&S algorithm main loop timer: 0.003999s (after merging)\n",
      "\n",
      "[t=0.003999s, 10188 KB] Next pair of indices: (20, 2)\n",
      "[t=0.003999s, 10188 KB] M&S algorithm main loop timer: 0.003999s (after computation of next merge)\n",
      "[t=0.007998s, 10188 KB] M&S algorithm main loop timer: 0.007998s (after label reduction)\n",
      "[t=0.007998s, 10188 KB] M&S algorithm main loop timer: 0.007998s (after shrinking)\n",
      "[t=0.007998s, 10188 KB] M&S algorithm main loop timer: 0.007998s (after merging)\n",
      "\n",
      "[t=0.007998s, 10188 KB] Next pair of indices: (21, 3)\n",
      "[t=0.007998s, 10188 KB] M&S algorithm main loop timer: 0.007998s (after computation of next merge)\n",
      "[t=0.016053s, 10188 KB] M&S algorithm main loop timer: 0.016053s (after label reduction)\n",
      "[t=0.016053s, 10188 KB] M&S algorithm main loop timer: 0.016053s (after shrinking)\n",
      "[t=0.016053s, 10188 KB] M&S algorithm main loop timer: 0.016053s (after merging)\n",
      "\n",
      "[t=0.016053s, 10188 KB] Next pair of indices: (22, 4)\n",
      "[t=0.016053s, 10188 KB] M&S algorithm main loop timer: 0.016053s (after computation of next merge)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after label reduction)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after shrinking)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after merging)\n",
      "\n",
      "[t=0.019990s, 10188 KB] Next pair of indices: (23, 5)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after computation of next merge)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after label reduction)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after shrinking)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after merging)\n",
      "\n",
      "[t=0.019990s, 10188 KB] Next pair of indices: (24, 6)\n",
      "[t=0.019990s, 10188 KB] M&S algorithm main loop timer: 0.019990s (after computation of next merge)\n",
      "[t=0.023990s, 10188 KB] M&S algorithm main loop timer: 0.023990s (after label reduction)\n",
      "[t=0.023990s, 10188 KB] M&S algorithm main loop timer: 0.023990s (after shrinking)\n",
      "[t=0.023990s, 10188 KB] M&S algorithm main loop timer: 0.023990s (after merging)\n",
      "\n",
      "[t=0.023990s, 10188 KB] Next pair of indices: (25, 7)\n",
      "[t=0.023990s, 10188 KB] M&S algorithm main loop timer: 0.023990s (after computation of next merge)\n",
      "[t=0.023990s, 10188 KB] M&S algorithm main loop timer: 0.023990s (after label reduction)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after shrinking)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after merging)\n",
      "\n",
      "[t=0.027990s, 10188 KB] Next pair of indices: (26, 8)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after computation of next merge)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after label reduction)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after shrinking)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after merging)\n",
      "\n",
      "[t=0.027990s, 10188 KB] Next pair of indices: (27, 9)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after computation of next merge)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after label reduction)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after shrinking)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after merging)\n",
      "\n",
      "[t=0.027990s, 10188 KB] Next pair of indices: (28, 10)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after computation of next merge)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after label reduction)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after shrinking)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after merging)\n",
      "\n",
      "[t=0.027990s, 10188 KB] Next pair of indices: (29, 11)\n",
      "[t=0.027990s, 10188 KB] M&S algorithm main loop timer: 0.027990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (30, 12)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (31, 13)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (32, 14)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (33, 15)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (34, 16)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (35, 17)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (36, 18)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] Next pair of indices: (37, 19)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after computation of next merge)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after label reduction)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after shrinking)\n",
      "[t=0.031990s, 10188 KB] M&S algorithm main loop timer: 0.031990s (after merging)\n",
      "\n",
      "[t=0.031990s, 10188 KB] End of merge-and-shrink algorithm, statistics:\n",
      "[t=0.031990s, 10188 KB] Main loop runtime: 0.031990s\n",
      "[t=0.031990s, 10188 KB] Maximum intermediate abstraction size: 39\n",
      "[t=0.031990s, 10188 KB] Final peak memory increase of merge-and-shrink algorithm: 0 KB\n",
      "[t=0.031990s, 10188 KB] Merge-and-shrink algorithm runtime: 0.031990s\n",
      "\n",
      "[t=0.031990s, 10188 KB] Number of remaining factors: 1\n",
      "[t=0.031990s, 10188 KB] Number of factors kept: 1\n",
      "[t=0.031990s, 10188 KB] Done initializing merge-and-shrink heuristic.\n",
      "\n",
      "[t=0.031990s, 10188 KB] Building successor generator...done!\n",
      "[t=0.031990s, 10188 KB] peak memory difference for successor generator creation: 0 KB\n",
      "[t=0.031990s, 10188 KB] time for successor generation creation: 0.000000s\n",
      "[t=0.031990s, 10188 KB] Variables: 20\n",
      "[t=0.031990s, 10188 KB] FactPairs: 121\n",
      "[t=0.031990s, 10188 KB] Bytes per state: 8\n",
      "[t=0.031990s, 10188 KB] Conducting best first search with reopening closed nodes, (real) bound = 2147483647\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 14\n",
      "[t=0.031990s, 10188 KB] g=0, 1 evaluated, 0 expanded\n",
      "[t=0.031990s, 10188 KB] f = 14, 1 evaluated, 0 expanded\n",
      "[t=0.031990s, 10188 KB] Initial heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 14\n",
      "[t=0.031990s, 10188 KB] pruning method: none\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 13\n",
      "[t=0.031990s, 10188 KB] g=1, 2 evaluated, 1 expanded\n",
      "[t=0.031990s, 10188 KB] f = 16, 3 evaluated, 2 expanded\n",
      "[t=0.031990s, 10188 KB] f = 18, 6 evaluated, 4 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 12\n",
      "[t=0.031990s, 10188 KB] g=6, 13 evaluated, 8 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 11\n",
      "[t=0.031990s, 10188 KB] g=7, 16 evaluated, 9 expanded\n",
      "[t=0.031990s, 10188 KB] f = 19, 20 evaluated, 11 expanded\n",
      "[t=0.031990s, 10188 KB] f = 20, 23 evaluated, 12 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 10\n",
      "[t=0.031990s, 10188 KB] g=10, 32 evaluated, 17 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 9\n",
      "[t=0.031990s, 10188 KB] g=11, 37 evaluated, 18 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 8\n",
      "[t=0.031990s, 10188 KB] g=12, 43 evaluated, 20 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 7\n",
      "[t=0.031990s, 10188 KB] g=13, 48 evaluated, 21 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 6\n",
      "[t=0.031990s, 10188 KB] g=14, 51 evaluated, 22 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 5\n",
      "[t=0.031990s, 10188 KB] g=15, 54 evaluated, 23 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 4\n",
      "[t=0.031990s, 10188 KB] g=16, 56 evaluated, 24 expanded\n",
      "[t=0.031990s, 10188 KB] f = 21, 115 evaluated, 51 expanded\n",
      "[t=0.031990s, 10188 KB] f = 22, 134 evaluated, 58 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 3\n",
      "[t=0.031990s, 10188 KB] g=19, 705 evaluated, 281 expanded\n",
      "[t=0.031990s, 10188 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 2\n",
      "[t=0.031990s, 10188 KB] g=20, 706 evaluated, 282 expanded\n",
      "[t=0.031990s, 10188 KB] f = 23, 956 evaluated, 378 expanded\n",
      "[t=0.031990s, 10188 KB] f = 24, 1062 evaluated, 413 expanded\n",
      "[t=0.039990s, 10476 KB] f = 25, 5665 evaluated, 2195 expanded\n",
      "[t=0.039990s, 10476 KB] f = 26, 6642 evaluated, 2486 expanded\n",
      "[t=0.043990s, 10608 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 1\n",
      "[t=0.043990s, 10608 KB] g=25, 9035 evaluated, 3517 expanded\n",
      "[t=0.043990s, 10608 KB] New best heuristic value for merge_and_shrink(merge_strategy=merge_precomputed(merge_tree=linear(variable_order=reverse_level)),shrink_strategy=shrink_bisimulation(greedy=true),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=infinity,threshold_before_merge=1): 0\n",
      "[t=0.043990s, 10608 KB] g=26, 9037 evaluated, 3518 expanded\n",
      "[t=0.043990s, 10608 KB] Solution found!\n",
      "[t=0.043990s, 10608 KB] Actual search time: 0.012000s\n",
      "unstack b9 b2 (1)\n",
      "putdown b9 (1)\n",
      "unstack b2 b10 (1)\n",
      "putdown b2 (1)\n",
      "unstack b10 b7 (1)\n",
      "stack b10 b2 (1)\n",
      "unstack b7 b4 (1)\n",
      "putdown b7 (1)\n",
      "unstack b4 b8 (1)\n",
      "stack b4 b7 (1)\n",
      "pickup b9 (1)\n",
      "stack b9 b4 (1)\n",
      "unstack b10 b2 (1)\n",
      "stack b10 b9 (1)\n",
      "unstack b8 b6 (1)\n",
      "putdown b8 (1)\n",
      "unstack b6 b3 (1)\n",
      "putdown b6 (1)\n",
      "unstack b3 b1 (1)\n",
      "stack b3 b10 (1)\n",
      "pickup b2 (1)\n",
      "stack b2 b1 (1)\n",
      "pickup b8 (1)\n",
      "stack b8 b2 (1)\n",
      "pickup b6 (1)\n",
      "stack b6 b8 (1)\n",
      "[t=0.043990s, 10608 KB] Plan length: 26 step(s).\n",
      "[t=0.043990s, 10608 KB] Plan cost: 26\n",
      "[t=0.043990s, 10608 KB] Expanded 3519 state(s).\n",
      "[t=0.043990s, 10608 KB] Reopened 0 state(s).\n",
      "[t=0.043990s, 10608 KB] Evaluated 9037 state(s).\n",
      "[t=0.043990s, 10608 KB] Evaluations: 9037\n",
      "[t=0.043990s, 10608 KB] Generated 14529 state(s).\n",
      "[t=0.043990s, 10608 KB] Dead ends: 0 state(s).\n",
      "[t=0.043990s, 10608 KB] Expanded until last jump: 2486 state(s).\n",
      "[t=0.043990s, 10608 KB] Reopened until last jump: 0 state(s).\n",
      "[t=0.043990s, 10608 KB] Evaluated until last jump: 6642 state(s).\n",
      "[t=0.043990s, 10608 KB] Generated until last jump: 10407 state(s).\n",
      "[t=0.043990s, 10608 KB] Number of registered states: 9037\n",
      "[t=0.043990s, 10608 KB] Int hash set load factor: 9037/16384 = 0.551575\n",
      "[t=0.043990s, 10608 KB] Int hash set resizes: 14\n",
      "[t=0.043990s, 10608 KB] Search time: 0.012000s\n",
      "[t=0.043990s, 10608 KB] Total time: 0.043990s\n",
      "Solution found.\n",
      "Peak memory: 10608 KB\n",
      "exitcode: 0\n",
      "\n",
      "Exit codes: [0]\n",
      "search exit code: 0\n",
      "\n",
      "INFO     Running validate.\n",
      "INFO     validate stdin: None\n",
      "INFO     validate time limit: None\n",
      "INFO     validate memory limit: None\n",
      "INFO     validate command line string: /home/jainav/Work/PE-LLM/VAL/validate ./domain/blocksworld/domain.pddl ./experiments/problems/llm_ic_pddl/p15.pddl ./experiments/plans/llm_ic_pddl/p15.pddl\n",
      "Checking plan: ./experiments/plans/llm_ic_pddl/p15.pddl\n",
      "Plan executed successfully - checking goal\n",
      "Plan valid\n",
      "Final value: 26 \n",
      "\n",
      "Successful plans:\n",
      "Value: 26\n",
      " ./experiments/plans/llm_ic_pddl/p15.pddl 26 \n",
      "\n",
      "validate exit code: 0\n",
      "\n",
      "INFO     Planner time: 0.21s\n",
      "[info] task 14 takes 20.007466077804565 sec, found a plan with cost 26.0\n"
     ]
    }
   ],
   "source": [
    "domain_name=\"blocksworld\"\n",
    "methods=[\"llm_ic_pddl_planner\",\"llm_pddl_planner\",\"llm_planner\",\"llm_ic_planner\"]\n",
    "method=methods[0]\n",
    "time_limit=200\n",
    "\n",
    "task_number=14\n",
    "tasks=[] # should be list of tuples like (descritpion, ground_truth_pddl)\n",
    "\n",
    "# Call the function to populate the tasks list\n",
    "tasks = get_tasks(domain_name)\n",
    "\n",
    "# 3. execute the llm planner\n",
    "method_function = {\n",
    "    \"llm_ic_pddl_planner\"   : llm_ic_pddl_planner,\n",
    "    \"llm_pddl_planner\"      : llm_pddl_planner,\n",
    "    \"llm_planner\"           : llm_planner,\n",
    "    \"llm_ic_planner\"        : llm_ic_planner, \n",
    "}[method]\n",
    "\n",
    "method_function(domain_name,time_limit,tasks,task_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain_name=\"blocksworld\"\n",
    "# methods=[\"llm_ic_pddl_planner\",\"llm_pddl_planner\",\"llm_planner\",\"llm_ic_planner\"]\n",
    "# for method in methods:\n",
    "#     time_limit=200\n",
    "#     for task_number in range(1,21):\n",
    "#         tasks=[] # should be list of tuples like (descritpion, ground_truth_pddl)\n",
    "\n",
    "#         # Call the function to populate the tasks list\n",
    "#         tasks = get_tasks(domain_name)\n",
    "\n",
    "#         # 3. execute the llm planner\n",
    "#         method_function = {\n",
    "#             \"llm_ic_pddl_planner\"   : llm_ic_pddl_planner,\n",
    "#             \"llm_pddl_planner\"      : llm_pddl_planner,\n",
    "#             \"llm_planner\"           : llm_planner,\n",
    "#             \"llm_ic_planner\"        : llm_ic_planner, \n",
    "#         }[method]\n",
    "\n",
    "#         method_function(domain_name,time_limit,tasks,task_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('p01.nl', 'p01.pddl'), ('p02.nl', 'p02.pddl'), ('p03.nl', 'p03.pddl'), ('p04.nl', 'p04.pddl'), ('p05.nl', 'p05.pddl'), ('p06.nl', 'p06.pddl'), ('p07.nl', 'p07.pddl'), ('p08.nl', 'p08.pddl'), ('p09.nl', 'p09.pddl'), ('p10.nl', 'p10.pddl'), ('p11.nl', 'p11.pddl'), ('p12.nl', 'p12.pddl'), ('p13.nl', 'p13.pddl'), ('p14.nl', 'p14.pddl'), ('p15.nl', 'p15.pddl'), ('p16.nl', 'p16.pddl'), ('p17.nl', 'p17.pddl'), ('p18.nl', 'p18.pddl'), ('p19.nl', 'p19.pddl'), ('p20.nl', 'p20.pddl')]\n"
     ]
    }
   ],
   "source": [
    "print(tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
